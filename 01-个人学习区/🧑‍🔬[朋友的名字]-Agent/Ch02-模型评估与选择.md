# Ch02-æ¨¡å‹è¯„ä¼°ä¸é€‰æ‹© - Agentè§†è§’

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡çš„æ•°å­¦åŸºç¡€

### ç»éªŒè¯¯å·®ä¸æ³›åŒ–è¯¯å·®

#### ç»éªŒè¯¯å·® (Empirical Error)
$$\hat{R}(h) = \frac{1}{n} \sum_{i=1}^n L(y_i, h(x_i))$$

å…¶ä¸­ï¼š
- $h$ æ˜¯å‡è®¾å‡½æ•°
- $L$ æ˜¯æŸå¤±å‡½æ•°
- $n$ æ˜¯è®­ç»ƒæ ·æœ¬æ•°é‡

#### æ³›åŒ–è¯¯å·® (Generalization Error)
$$R(h) = \mathbb{E}_{(x,y) \sim D}[L(y, h(x))]$$

#### è¯¯å·®åˆ†è§£
$$R(h) = \text{Bias}^2(h) + \text{Var}(h) + \text{Noise}$$

- **åå·®**: æ¨¡å‹çš„æœŸæœ›é¢„æµ‹ä¸çœŸå®å€¼çš„å·®å¼‚
- **æ–¹å·®**: æ¨¡å‹é¢„æµ‹çš„æ³¢åŠ¨æ€§
- **å™ªå£°**: æ•°æ®æœ¬èº«çš„å™ªå£°

### åå·®-æ–¹å·®æƒè¡¡

#### åå·®-æ–¹å·®å›°å¢ƒ
- **é«˜åå·®**: æ¨¡å‹è¿‡äºç®€å•ï¼Œæ— æ³•æ•æ‰æ•°æ®ä¸­çš„æ¨¡å¼
- **é«˜æ–¹å·®**: æ¨¡å‹è¿‡äºå¤æ‚ï¼Œå¯¹è®­ç»ƒæ•°æ®è¿‡æ‹Ÿåˆ
- **æƒè¡¡**: éœ€è¦åœ¨åå·®å’Œæ–¹å·®ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ç‚¹

#### æ•°å­¦è¡¨è¾¾
$$\mathbb{E}[(y - \hat{f}(x))^2] = \text{Bias}^2[\hat{f}(x)] + \text{Var}[\hat{f}(x)] + \sigma^2$$

å…¶ä¸­ï¼š
- $\text{Bias}[\hat{f}(x)] = \mathbb{E}[\hat{f}(x)] - f(x)$
- $\text{Var}[\hat{f}(x)] = \mathbb{E}[\hat{f}(x)^2] - \mathbb{E}[\hat{f}(x)]^2$
- $\sigma^2$ æ˜¯å™ªå£°æ–¹å·®

## ğŸ¯ åˆ†ç±»é—®é¢˜è¯„ä¼°æŒ‡æ ‡

### äºŒåˆ†ç±»è¯„ä¼°

#### æ··æ·†çŸ©é˜µ
```
                é¢„æµ‹æ­£ä¾‹    é¢„æµ‹è´Ÿä¾‹
å®é™…æ­£ä¾‹        TP           FN
å®é™…è´Ÿä¾‹        FP           TN
```

#### åŸºæœ¬æŒ‡æ ‡
- **å‡†ç¡®ç‡**: $\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}$
- **ç²¾ç¡®ç‡**: $\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$
- **å¬å›ç‡**: $\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$
- **F1åˆ†æ•°**: $\text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$

#### ç»¼åˆæŒ‡æ ‡
- **é©¬ä¿®æ–¯ç›¸å…³ç³»æ•°**: 
$$\text{MCC} = \frac{\text{TP} \times \text{TN} - \text{FP} \times \text{FN}}{\sqrt{(\text{TP}+\text{FP})(\text{TP}+\text{FN})(\text{TN}+\text{FP})(\text{TN}+\text{FN})}}$$

- **Kappaç³»æ•°**: è¡¡é‡åˆ†ç±»å™¨ä¸éšæœºåˆ†ç±»çš„ä¸€è‡´æ€§

### å¤šåˆ†ç±»è¯„ä¼°

#### å®å¹³å‡ (Macro-averaging)
- **å®ç²¾ç¡®ç‡**: $\text{Macro-P} = \frac{1}{K} \sum_{k=1}^K P_k$
- **å®å¬å›ç‡**: $\text{Macro-R} = \frac{1}{K} \sum_{k=1}^K R_k$
- **å®F1**: $\text{Macro-F1} = \frac{1}{K} \sum_{k=1}^K F1_k$

#### å¾®å¹³å‡ (Micro-averaging)
- **å¾®ç²¾ç¡®ç‡**: $\text{Micro-P} = \frac{\sum_{k=1}^K \text{TP}_k}{\sum_{k=1}^K (\text{TP}_k + \text{FP}_k)}$
- **å¾®å¬å›ç‡**: $\text{Micro-R} = \frac{\sum_{k=1}^K \text{TP}_k}{\sum_{k=1}^K (\text{TP}_k + \text{FN}_k)}$
- **å¾®F1**: $\text{Micro-F1} = 2 \times \frac{\text{Micro-P} \times \text{Micro-R}}{\text{Micro-P} + \text{Micro-R}}$

## ğŸ“ˆ å›å½’é—®é¢˜è¯„ä¼°æŒ‡æ ‡

### åŸºç¡€æŒ‡æ ‡

#### å‡æ–¹è¯¯å·® (MSE)
$$\text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$$

#### å¹³å‡ç»å¯¹è¯¯å·® (MAE)
$$\text{MAE} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|$$

#### å‡æ–¹æ ¹è¯¯å·® (RMSE)
$$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}$$

### ç›¸å¯¹æŒ‡æ ‡

#### å†³å®šç³»æ•° (RÂ²)
$$R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}$$

#### è°ƒæ•´RÂ²
$$\bar{R}^2 = 1 - (1-R^2)\frac{n-1}{n-p-1}$$

å…¶ä¸­ $p$ æ˜¯ç‰¹å¾æ•°é‡ã€‚

#### å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (MAPE)
$$\text{MAPE} = \frac{100\%}{n} \sum_{i=1}^n \left|\frac{y_i - \hat{y}_i}{y_i}\right|$$

## ğŸ”„ äº¤å‰éªŒè¯æŠ€æœ¯

### kæŠ˜äº¤å‰éªŒè¯

#### ç®—æ³•æ­¥éª¤
1. å°†æ•°æ®é›†éšæœºåˆ†æˆkä¸ªå¤§å°ç›¸ç­‰çš„å­é›†
2. å¯¹äºæ¯ä¸ªå­é›†iï¼š
   - ä½¿ç”¨ç¬¬iä¸ªå­é›†ä½œä¸ºéªŒè¯é›†
   - ä½¿ç”¨å…¶ä½™k-1ä¸ªå­é›†ä½œä¸ºè®­ç»ƒé›†
   - è®­ç»ƒæ¨¡å‹å¹¶è®¡ç®—éªŒè¯è¯¯å·®
3. è®¡ç®—kæ¬¡éªŒè¯è¯¯å·®çš„å¹³å‡å€¼

#### æ•°å­¦è¡¨è¾¾
$$\text{CV}_k = \frac{1}{k} \sum_{i=1}^k \frac{1}{|D_i|} \sum_{(x,y) \in D_i} L(y, h^{(-i)}(x))$$

å…¶ä¸­ $h^{(-i)}$ æ˜¯åœ¨ä¸åŒ…å«ç¬¬iä¸ªå­é›†çš„æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚

#### å¤æ‚åº¦åˆ†æ
- **æ—¶é—´å¤æ‚åº¦**: $O(k \times T_{\text{train}})$
- **ç©ºé—´å¤æ‚åº¦**: $O(|D|)$
- **è®¡ç®—ä»£ä»·**: éšç€kçš„å¢åŠ è€Œå¢åŠ 

### ç•™ä¸€æ³•äº¤å‰éªŒè¯ (LOOCV)

#### ç‰¹ç‚¹
- $k = n$ï¼Œæ¯ä¸ªæ ·æœ¬å•ç‹¬ä½œä¸ºéªŒè¯é›†
- å‡ ä¹æ— åï¼Œä½†è®¡ç®—æˆæœ¬é«˜
- é€‚åˆå°æ•°æ®é›†

#### æ•°å­¦è¡¨è¾¾
$$\text{LOOCV} = \frac{1}{n} \sum_{i=1}^n L(y_i, h^{(-i)}(x_i))$$

### è‡ªåŠ©æ³• (Bootstrap)

#### é‡é‡‡æ ·æŠ€æœ¯
1. ä»è®­ç»ƒé›†ä¸­æœ‰æ”¾å›åœ°é‡‡æ ·nä¸ªæ ·æœ¬
2. ä½¿ç”¨é‡‡æ ·çš„æ ·æœ¬è®­ç»ƒæ¨¡å‹
3. ä½¿ç”¨æœªé‡‡æ ·çš„æ ·æœ¬è¿›è¡ŒéªŒè¯
4. é‡å¤å¤šæ¬¡ï¼Œè®¡ç®—å¹³å‡æ€§èƒ½

#### æ•°å­¦è¡¨è¾¾
$$\text{Bootstrap} = \frac{1}{B} \sum_{b=1}^B \frac{1}{|D_b^c|} \sum_{(x,y) \in D_b^c} L(y, h_b(x))$$

å…¶ä¸­ $D_b$ æ˜¯ç¬¬bæ¬¡é‡‡æ ·çš„è®­ç»ƒé›†ï¼Œ$D_b^c$ æ˜¯å¯¹åº”çš„éªŒè¯é›†ã€‚

## ğŸ›ï¸ å‡è®¾æ£€éªŒ

### ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ

#### tæ£€éªŒ
ç”¨äºæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„æ€§èƒ½å·®å¼‚æ˜¯å¦æ˜¾è‘—ã€‚

$$t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$$

å…¶ä¸­ï¼š
- $\bar{x}_1, \bar{x}_2$ æ˜¯ä¸¤ä¸ªæ¨¡å‹çš„å¹³å‡æ€§èƒ½
- $s_1^2, s_2^2$ æ˜¯ä¸¤ä¸ªæ€§èƒ½çš„æ–¹å·®
- $n_1, n_2$ æ˜¯æµ‹è¯•æ¬¡æ•°

#### æ–¹å·®åˆ†æ (ANOVA)
ç”¨äºæ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„æ€§èƒ½å·®å¼‚ã€‚

$$F = \frac{\text{MS}_{\text{between}}}{\text{MS}_{\text{within}}}$$

### ç½®ä¿¡åŒºé—´

#### æ€§èƒ½å·®å¼‚çš„ç½®ä¿¡åŒºé—´
$$\text{CI} = (\bar{d} - t_{\alpha/2} \times \frac{s_d}{\sqrt{n}}, \bar{d} + t_{\alpha/2} \times \frac{s_d}{\sqrt{n}})$$

å…¶ä¸­ï¼š
- $\bar{d}$ æ˜¯æ€§èƒ½å·®å¼‚çš„å¹³å‡å€¼
- $s_d$ æ˜¯æ€§èƒ½å·®å¼‚çš„æ ‡å‡†å·®
- $n$ æ˜¯æµ‹è¯•æ¬¡æ•°

## ğŸ¤– Agentç³»ç»Ÿä¸­çš„å®é™…åº”ç”¨

### åœ¨çº¿è¯„ä¼°ç­–ç•¥

#### æµå¼æ•°æ®è¯„ä¼°
```python
class OnlineEvaluator:
    def __init__(self, window_size=1000):
        self.window_size = window_size
        self.recent_predictions = []
        self.recent_labels = []
    
    def add_result(self, prediction, label):
        self.recent_predictions.append(prediction)
        self.recent_labels.append(label)
        
        if len(self.recent_predictions) > self.window_size:
            self.recent_predictions.pop(0)
            self.recent_labels.pop(0)
    
    def get_current_metrics(self):
        if len(self.recent_predictions) < 100:
            return None
        
        return self.calculate_metrics(self.recent_predictions, self.recent_labels)
```

#### å»¶è¿Ÿåé¦ˆå¤„ç†
```python
class DelayedFeedbackEvaluator:
    def __init__(self, max_delay=3600):
        self.max_delay = max_delay
        self.pending_predictions = {}
    
    def add_prediction(self, prediction_id, prediction, timestamp):
        self.pending_predictions[prediction_id] = {
            'prediction': prediction,
            'timestamp': timestamp
        }
    
    def add_feedback(self, prediction_id, label, feedback_timestamp):
        if prediction_id in self.pending_predictions:
            pred_info = self.pending_predictions[prediction_id]
            delay = feedback_timestamp - pred_info['timestamp']
            
            if delay <= self.max_delay:
                self.evaluate_with_delay(
                    pred_info['prediction'], 
                    label, 
                    delay
                )
            
            del self.pending_predictions[prediction_id]
```

### å¤šç›®æ ‡ä¼˜åŒ–

#### å¸•ç´¯æ‰˜æœ€ä¼˜
```python
class MultiObjectiveOptimizer:
    def __init__(self, objectives):
        self.objectives = objectives
    
    def is_pareto_dominated(self, point, other_points):
        for other in other_points:
            if all(other[obj] >= point[obj] for obj in self.objectives) and \
               any(other[obj] > point[obj] for obj in self.objectives):
                return True
        return False
    
    def find_pareto_front(self, points):
        pareto_front = []
        for point in points:
            if not self.is_pareto_dominated(point, points):
                pareto_front.append(point)
        return pareto_front
```

#### åŠ æƒå’Œæ–¹æ³•
```python
def weighted_sum_score(metrics, weights):
    """
    å¤šç›®æ ‡åŠ æƒè¯„åˆ†
    metrics: dict of metric_name -> value
    weights: dict of metric_name -> weight
    """
    total_score = 0
    for metric_name, value in metrics.items():
        if metric_name in weights:
            total_score += weights[metric_name] * value
    return total_score
```

### æ¨¡å‹é€‰æ‹©ç­–ç•¥

#### åŸºäºå¤æ‚åº¦çš„é€‰æ‹©
```python
def select_model_by_complexity(candidates, complexity_threshold):
    """
    åŸºäºå¤æ‚åº¦é˜ˆå€¼é€‰æ‹©æ¨¡å‹
    """
    acceptable_models = []
    for model in candidates:
        if model.complexity <= complexity_threshold:
            acceptable_models.append(model)
    
    if not acceptable_models:
        # å¦‚æœæ²¡æœ‰ç¬¦åˆå¤æ‚åº¦è¦æ±‚çš„æ¨¡å‹ï¼Œé€‰æ‹©æœ€ç®€å•çš„
        return min(candidates, key=lambda x: x.complexity)
    
    # åœ¨å¯æ¥å—çš„æ¨¡å‹ä¸­é€‰æ‹©æ€§èƒ½æœ€å¥½çš„
    return max(acceptable_models, key=lambda x: x.performance)
```

#### åŸºäºèµ„æºçº¦æŸçš„é€‰æ‹©
```python
def select_model_with_constraints(candidates, constraints):
    """
    åŸºäºèµ„æºçº¦æŸé€‰æ‹©æ¨¡å‹
    constraints: dict of resource_name -> max_value
    """
    feasible_models = []
    
    for model in candidates:
        feasible = True
        for resource, max_value in constraints.items():
            if getattr(model, resource) > max_value:
                feasible = False
                break
        
        if feasible:
            feasible_models.append(model)
    
    if not feasible_models:
        return None
    
    return max(feasible_models, key=lambda x: x.performance)
```

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

### è®¡ç®—æ•ˆç‡ä¼˜åŒ–

#### å¢é‡è¯„ä¼°
```python
class IncrementalEvaluator:
    def __init__(self):
        self.total_metrics = {}
        self.count = 0
    
    def add_batch(self, predictions, labels):
        batch_metrics = self.calculate_metrics(predictions, labels)
        
        if self.count == 0:
            self.total_metrics = batch_metrics
        else:
            for metric in batch_metrics:
                self.total_metrics[metric] = (
                    self.total_metrics[metric] * self.count + 
                    batch_metrics[metric] * len(predictions)
                ) / (self.count + len(predictions))
        
        self.count += len(predictions)
        return self.total_metrics
```

#### å¹¶è¡Œè¯„ä¼°
```python
from concurrent.futures import ThreadPoolExecutor
import numpy as np

class ParallelEvaluator:
    def __init__(self, n_workers=4):
        self.n_workers = n_workers
    
    def parallel_evaluate(self, model, test_data_chunks):
        def evaluate_chunk(chunk):
            predictions = model.predict(chunk['X'])
            return self.calculate_metrics(predictions, chunk['y'])
        
        with ThreadPoolExecutor(max_workers=self.n_workers) as executor:
            results = list(executor.map(evaluate_chunk, test_data_chunks))
        
        return self.aggregate_metrics(results)
```

### å†…å­˜æ•ˆç‡ä¼˜åŒ–

#### æµå¼è¯„ä¼°
```python
class StreamingEvaluator:
    def __init__(self, chunk_size=1000):
        self.chunk_size = chunk_size
        self.metrics_aggregator = None
    
    def evaluate_streaming(self, model, data_stream):
        chunk = []
        
        for sample in data_stream:
            chunk.append(sample)
            
            if len(chunk) >= self.chunk_size:
                chunk_metrics = self.evaluate_chunk(model, chunk)
                self.metrics_aggregator = self.aggregate_chunk_metrics(
                    self.metrics_aggregator, chunk_metrics
                )
                chunk = []
        
        # å¤„ç†å‰©ä½™æ•°æ®
        if chunk:
            chunk_metrics = self.evaluate_chunk(model, chunk)
            self.metrics_aggregator = self.aggregate_chunk_metrics(
                self.metrics_aggregator, chunk_metrics
            )
        
        return self.metrics_aggregator
```

## ğŸ“Š å®ç°è€ƒè™‘

### ä»£ç ç»“æ„è®¾è®¡

#### è¯„ä¼°å™¨åŸºç±»
```python
from abc import ABC, abstractmethod
import numpy as np

class BaseEvaluator(ABC):
    def __init__(self):
        self.metrics_history = []
    
    @abstractmethod
    def calculate_metrics(self, predictions, labels):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        pass
    
    def evaluate_model(self, model, test_data):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        predictions = model.predict(test_data['X'])
        metrics = self.calculate_metrics(predictions, test_data['y'])
        self.metrics_history.append(metrics)
        return metrics
    
    def get_average_metrics(self):
        """è·å–å¹³å‡æ€§èƒ½"""
        if not self.metrics_history:
            return None
        
        avg_metrics = {}
        for metric in self.metrics_history[0]:
            avg_metrics[metric] = np.mean([
                m[metric] for m in self.metrics_history
            ])
        
        return avg_metrics
```

#### åˆ†ç±»è¯„ä¼°å™¨
```python
class ClassificationEvaluator(BaseEvaluator):
    def calculate_metrics(self, predictions, labels):
        from sklearn.metrics import (
            accuracy_score, precision_score, 
            recall_score, f1_score, roc_auc_score
        )
        
        metrics = {
            'accuracy': accuracy_score(labels, predictions),
            'precision': precision_score(labels, predictions, average='weighted'),
            'recall': recall_score(labels, predictions, average='weighted'),
            'f1': f1_score(labels, predictions, average='weighted')
        }
        
        # å¦‚æœæ˜¯äºŒåˆ†ç±»ï¼Œæ·»åŠ AUC
        if len(np.unique(labels)) == 2:
            try:
                metrics['auc'] = roc_auc_score(labels, predictions)
            except:
                metrics['auc'] = 0.5
        
        return metrics
```

#### å›å½’è¯„ä¼°å™¨
```python
class RegressionEvaluator(BaseEvaluator):
    def calculate_metrics(self, predictions, labels):
        from sklearn.metrics import (
            mean_squared_error, mean_absolute_error, r2_score
        )
        
        metrics = {
            'mse': mean_squared_error(labels, predictions),
            'mae': mean_absolute_error(labels, predictions),
            'rmse': np.sqrt(mean_squared_error(labels, predictions)),
            'r2': r2_score(labels, predictions)
        }
        
        return metrics
```

## ğŸ“ å­¦ä¹ æ€»ç»“

### å…³é”®æ´å¯Ÿ
1. **ç†è®ºåŸºç¡€**: æ‰å®çš„æ•°å­¦ç†è®ºæ˜¯æ­£ç¡®é€‰æ‹©è¯„ä¼°æŒ‡æ ‡çš„åŸºç¡€
2. **å®è·µè€ƒé‡**: åœ¨å®é™…åº”ç”¨ä¸­éœ€è¦è€ƒè™‘è®¡ç®—å¤æ‚åº¦å’Œèµ„æºé™åˆ¶
3. **ä¸Šä¸‹æ–‡ç›¸å…³**: ä¸åŒçš„åº”ç”¨åœºæ™¯éœ€è¦ä¸åŒçš„è¯„ä¼°ç­–ç•¥

### å®è·µè®¡åˆ’
- [ ] å®ç°ä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹è¯„ä¼°æ¡†æ¶
- [ ] ä¼˜åŒ–è¯„ä¼°è¿‡ç¨‹çš„è®¡ç®—æ•ˆç‡
- [ ] åœ¨Agentç³»ç»Ÿä¸­åº”ç”¨åœ¨çº¿è¯„ä¼°æŠ€æœ¯

## ğŸ¤” æŠ€æœ¯ç–‘é—®

### ç†è®ºé—®é¢˜
- å¦‚ä½•åœ¨éç‹¬ç«‹åŒåˆ†å¸ƒæ•°æ®ä¸Šè¿›è¡Œæœ‰æ•ˆçš„æ¨¡å‹è¯„ä¼°ï¼Ÿ
- å¦‚ä½•å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜å¯¹è¯„ä¼°æŒ‡æ ‡çš„å½±å“ï¼Ÿ
- å¦‚ä½•è®¾è®¡é€‚åˆAgentç³»ç»Ÿçš„å¢é‡è¯„ä¼°æ–¹æ³•ï¼Ÿ

### å®ç°é—®é¢˜
- å¦‚ä½•åœ¨é«˜ç»´ç©ºé—´ä¸­æœ‰æ•ˆè®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼Ÿ
- å¦‚ä½•å¤„ç†å®æ—¶æ•°æ®æµä¸­çš„æ¨¡å‹æ¼‚ç§»æ£€æµ‹ï¼Ÿ
- å¦‚ä½•è®¾è®¡é«˜æ•ˆçš„äº¤å‰éªŒè¯å¹¶è¡Œç®—æ³•ï¼Ÿ

## ğŸ“Š ç›¸å…³é“¾æ¥

**å…±äº«è®¨è®ºåŒº**: [[ğŸ’¬ä¸“é¢˜è®¨è®ºåŒº/Ch02-æ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©-è®¨è®º]]

**å­¦ä¹ èµ„æº**: [[ğŸ”—å­¦ä¹ èµ„æ–™æ±‡æ€»]]

**ä¸ªäººç¬”è®°**: 
- [[Ch01-ç»ªè®º|ä¸Šä¸€ç« ]]
- [[Ch03-çº¿æ€§æ¨¡å‹|ä¸‹ä¸€ç« ]]
- [[ğŸ“šæ ¸å¿ƒæœ¯è¯­è¡¨|æœ¯è¯­è¡¨]]